## 자료구조

# 1. 시간복잡도와 공간복잡도

<details>
<summary>시간복잡도와 공간복잡도에 대해 아는만큼 설명해주세요</summary>

- 둘 다 입력 크기 N이 커질수록 성능이 어떻게 변하는지를 보는 척도로, 주로 Big-O 표기법을 사용해 표현하며, 최악의 경우를 기준으로 작성하는 경우가 많습니다.
- 시간 복잡도는 알고리즘이 실행되는 데 걸리는 시간,
- 공간 복잡도는 알고리즘이 사용하는 메모리 양을 나타냅니다.

</details>

<details>
<summary>Big-O, Big-Theta, Big-Omega 에 대해 설명해 주세요</summary>

- Big-O, Big-Theta, Big-Omega는 알고리즘의 복잡도를 입력 크기 n에 따라 표현하는 표기법입니다.
- Big-O 표기법은 알고리즘이 최악의 경우 얼마나 오래 걸릴 수 있는지를 나타냅니다.
- Big-Ω 표기법은 알고리즘의 최선의 경우, 즉 가장 빠를 때 어느 정도로 성능이 나올 수 있는지를 나타냅니다.
- Big-Θ는 입력 크기가 커졌을 때 알고리즘의 수행 시간이 최악과 최선이 동일한 수준에서 수렴할 경우 사용하는 표현으로, 정확한 성능을 나타냅니다.

</details>

<details>
<summary>다른 것을 사용하지 않고, Big-O를 사용하는 이유가 있을까요?</summary>

- Big-O를 주로 사용하는 이유는 Big-O가 최악의 경우를 보장하기 때문에 실무에서 안정적인 성능 예측이 가능하기 때문입니다.

</details>

<details>
<summary>O(1)은 O(N²) 보다 무조건적으로 빠른가요?</summary>

- O(1)이 O(n²)보다 무조건적으로 빠르지는 않습니다.
  - 예를 들어, O(1) 알고리즘이 10초가 걸리고, O(N²) 알고리즘이 N²/10초가 걸린다고 가정해봅시다.
  - 이때 N=10이면 둘 다 10초지만,
  - N이 더 작으면 O(N²)가 더 빠를 수 있습니다.
- 복잡도 계산은 성능 추세를 표현하기 위하여 입력 크기 N이 무한대로 향할 때를 가정하기 때문에 상수를 무시하지만, 실제 실행 시간은 상수에 따라 달라질 수 있습니다.

</details>

# 2. 링크드리스트

<details>
<summary>일반 배열과, 링크드 리스트를 비교해 주세요</summary>

- ArrayList는 내부적으로 배열 기반의 자료구조입니다.
- 인덱스를 통해 즉시 접근이 가능하기 때문에 검색 속도가 O(1)로 빠릅니다.
- 하지만 배열은 메모리 공간이 연속되어야 하고, 중간에 데이터를 삽입하거나 삭제하면 나머지 데이터를 이동시켜야 하므로 O(n)의 시간이 걸립니다.
- 반면 LinkedList는 노드와 포인터로 구성된 연결 구조입니다.
- 각 노드가 다음 노드를 가리키는 방식으로 연결되어 있기 때문에, 중간 삽입이나 삭제는 포인터만 조작하면 되어 O(1)로 가능합니다.
- 하지만 인덱스를 기반으로 한 임의 접근은 불가능하여, 임의 위치 접근 시 O(n)의 접근 시간이 소요됩니다.
- 배열은 읽기 속도가 중요한 경우, 연결 리스트는 삽입과 삭제가 빈번한 경우에 적합합니다.

</details>

<details>
<summary>링크드 리스트를 사용해서 구현할 수 있는 다른 자료구조에 대해 설명해 주세요</summary>

- 배열로 구현할 수 있는 자료구조는 대부분 만들 수 있으며, 대표적으로 스택(Stack)과 큐(Queue)가 있습니다.

</details>

# 3. 스택과 큐

<details>
<summary>스택과 큐에 대해 설명해주세요</summary>

- 스택은 Last In First Out을 하는 자료구조로, 연결 리스트의 앞부분에 노드를 삽입하거나 삭제하는 방식으로 구현할 수 있습니다.
- 큐는 First In First Out을 하는 자료구조로, 앞에서 꺼내고 뒤에 삽입하는 구조를 연결 리스트를 통해 구현할 수 있습니다.

</details>

<details>
<summary>스택 2개로 큐를, 큐 2개로 스택을 만드는 방법과, 그 시간복잡도에 대해 설명해 주세요</summary>

- 스택 2개로 큐를 구현할 수 있습니다. 하나의 스택에는 데이터를 그대로 넣고, 데이터를 꺼낼 때는 두 번째 스택으로 데이터를 옮겨 순서를 뒤집어줍니다.
- 이렇게 하면 삽입 연산은 O(1)로 빠르지만, 꺼낼 때 stack2가 비어 있으면 모든 데이터를 옮겨야 해서 최악의 경우 O(n)이 걸립니다. 하지만 이 작업은 한 번만 발생하므로 평균적으로는 O(1)입니다.
- 구체적인 과정:

  - 초기 enqueue 연산
    - inStack: [1, 2, 3]
    - outStack: []
  - dequeue() 실행
    - outStack이 비어 있으므로 → inStack의 데이터를 꺼내서 outStack에 넣음
    - → outStack: [3, 2, 1]
    - outStack.pop() → 1 출력됨 ✅
  - enqueue(4)
    - 새 데이터는 그냥 inStack에 push함 → [4]
    - outStack: 아직 [3, 2]가 남아 있음
  - enqueue(1), enqueue(2), enqueue(3)
- 반대로 큐를 이용해서 스택 LIFO처럼 동작하게 하려면, 최근에 넣은 데이터가 큐의 앞에 오도록 넣을 때 순서를 미리 바꿔줘야 합니다.
- 이 방식은 push 연산이 O(n)으로 느려지지만, pop은 O(1)로 빠르게 처리됩니다.

</details>

<details>
<summary>시간복잡도를 유지하면서, 배열로 스택과 큐를 구현할 수 있을까요?</summary>

- 스택은 배열로 쉽게 구현할 수 있습니다.
  - 배열의 끝을 top으로 사용하면 push와 pop 연산 모두 O(1)로 수행 가능하며, 시간복잡도를 유지할 수 있습니다.
- 큐의 경우는 조금 더 주의가 필요합니다.
  - 일반적으로 배열의 앞에서 데이터를 제거하면 O(n)의 시간이 걸리지만,
  - 미리 충분한 빈 공간을 확보한 후, 배열의 중간 지점을 큐의 head로 시작하면
  - 양쪽으로 포인터를 이동시키며 enqueue, dequeue 연산을 O(1)에 가깝게 처리할 수 있습니다.

</details>

<details>
<summary>Prefix, Infix, Postfix 에 대해 설명하고, 이를 스택을 활용해서 계산하는 방법에 대해 설명해 주세요</summary>

- 수식은 연산자의 위치에 따라 Infix(중위), Prefix(전위), Postfix(후위)로 나눌 수 있습니다.
- Infix는 일반적으로 사용하는 표기로, 피연산자 사이에 연산자가 위치합니다. 예: 2 + 3
- Prefix는 연산자가 앞에 위치합니다. 예: + 2 3
- Postfix는 연산자가 뒤에 위치합니다. 예: 2 3 +
- 컴퓨터는 괄호가 필요 없는 Postfix나 Prefix 형태가 처리에 유리합니다.
- 특히 Postfix는 스택을 사용하여 간단하게 계산할 수 있습니다.

  - 수식을 왼쪽에서 오른쪽으로 읽으면서
    - 피연산자를 만나면 스택에 push합니다.
    - 연산자를 만나면 스택에서 두 개의 피연산자를 pop하여 계산한 뒤, 결과를 다시 push합니다.
    - 수식을 끝까지 처리한 후 스택에 남은 값이 결과입니다.
  - 예: 2 3 + 5 *
    - 2, 3 push
    - `+` → 2 + 3 = 5 → push
    - 5 push
    - `*` → 5 * 5 = 25 → 결과
- Prefix도 비슷한 원리로, 수식을 오른쪽부터 읽으며 스택을 활용해 계산합니다.

</details>

<details>
<summary>Deque는 어떻게 구현할 수 있을까요?</summary>

- Deque(Double-ended Queue)는 한쪽에서만 삽입/삭제가 가능한 일반 큐와 달리, 양쪽에서 삽입과 삭제가 모두 가능한 선형 자료구조입니다.
- 구현방식1. 배열기반 Deque

  - 원형 큐(Circular Queue) 형태로 구현
  - front와 rear 포인터를 사용하여 인덱스를 순환시킴
  - 크기가 고정되어 있어 용량을 초과하면 확장 비용 발생
- 구현방식2. 이중 연결 리스트 기반 Deque

  - 양쪽에 삽입/삭제가 빠름(O(1))
  - 동적 메모리 할당으로 크기 제한 없음
  - 포인터를 이용하므로 구현이 더 복잡함
- Deque는 캐시, 슬라이딩 윈도우에서 사용됩니다.

  - 가장 오래 사용하지 않은 데이터를 제거하는 방식의 캐시 전략
    - 앞(front) → 가장 오래된 데이터 제거
    - 뒤(rear) → 새로 사용한 데이터를 삽입

</details>

<details>
<summary>(C++ 한정) Deque의 Random Access 시간복잡도는 O(1) 입니다. 이게 어떻게 가능한걸까요?</summary>

- C++의 `std::deque`는 여러 개의 고정 크기 블록을 연결한 구조를 사용합니다.
- 각 블록은 포인터 배열(map)에 의해 관리되며, 인덱스 접근 시 해당 블록과 오프셋을 계산하여 바로 접근할 수 있기 때문에
- 논리적 인덱스를 O(1) 시간에 물리적 위치로 매핑할 수 있습니다.
- 이 구조 덕분에 `std::deque[i]` 접근이 평균적으로 O(1)로 처리됩니다.

</details>

# 4. 해시

<details>
<summary>해시 자료구조에 대해 설명해주세요</summary>

- 해시 자료구조는 키-값(Key-Value) 쌍을 저장하는 자료구조로
- 해시 함수를 사용하여 키를 고유한 인덱스로 변환 → 빠르게 데이터 저장/접근 가능 (O(1))

</details>

<details>
<summary>값이 주어졌을 때, 어떻게 하면 충돌이 최대한 적은 해시 함수를 설계할 수 있을까요?</summary>

- 해시 함수에서 충돌이 발생할 수 있는 이유: 해시 함수는 유한한 범위의 정수로 매핑되므로, 서로 다른 키가 같은 인덱스로 매핑될 수 있음
- 충돌을 최소화하려면 균일한 분포를 생성할 수 있는 해시 함수를 설계해야 합니다.
- 소수를 사용한 모듈러 연산이 효과적

</details>

<details>
<summary>해시값이 충돌했을 때, 어떤 방식으로 처리할 수 있을까요?</summary>

- Chaining: 각 버킷에 연결 리스트를 사용하여 충돌된 값을 저장

  - 장점: 간단, 동적 크기 관리 가능
  - 단점: 최악의 경우 O(n) (모두 같은 버킷으로 모일 때)
- Open Addressing (개방 주소법): 빈 버킷을 찾아 충돌된 값을 저장

  - 장점: 메모리 절약
  - 단점: 클러스터링(Cluster) 발생 위험

</details>

<details>
<summary>본인이 사용하는 언어에서는, 어떤 방식으로 해시 충돌을 처리하나요?</summary>

- Java의 HashMap은 기본적으로 Chaining 방식을 사용하여 충돌을 처리합니다.
- 각 버킷은 LinkedList로 시작하지만, 충돌 수가 많아질 경우 TreeNode (Red-Black Tree)로 전환됩니다.
- 이러한 구조 덕분에 최악의 경우 O(n)에서 O(log n)으로 성능을 개선할 수 있습니다.

</details>

<details>
<summary>Double Hashing 의 장점과 단점에 대해서 설명하고, 단점을 어떻게 해결할 수 있을지 설명해 주세요</summary>

- Double Hashing은 두 개의 해시 함수를 사용하여 충돌을 해결하는 방식입니다.
- 장점: 클러스터링(Cluster) 문제가 적음 (Linear, Quadratic Probing보다)
- 단점: 두 번째 해시 함수가 0이 될 경우 무한 루프 발생 위험
- 해결 방안: 두 번째 해시 함수는 항상 홀수로 설정하거나, 테이블 크기를 소수로 유지

</details>

<details>
<summary>Load Factor에 대해 설명해 주세요. 본인이 사용하는 언어에서의 해시 자료구조는 Load Factor에 관련한 정책이 어떻게 구성되어 있나요?</summary>

- Load Factor는 해시 테이블이 얼마나 채워졌는지를 나타내는 비율입니다.
- 기본적으로 Java의 HashMap은 Load Factor 0.75로 설정되어 있습니다.
  - 이는 버킷이 75% 차면 크기를 두 배로 늘려 성능을 유지하도록 합니다.

</details>

<details>
<summary>다른 자료구조와 비교하여, 해시 테이블은 멀티스레드 환경에서 심각한 수준의 Race Condition 문제에 빠질 위험이 있습니다. 성능 감소를 최소화 한 채로 해당 문제를 해결할 수 있는 방법을 설계해 보세요</summary>

- 멀티스레드 환경에서 Race Condition을 피하려면 ConcurrentHashMap을 사용하는 것이 일반적입니다.
- 분할 잠금 방식(Stripe Lock)으로 성능 저하를 최소화하면서도 동시성을 보장할 수 있습니다.

</details>

# 5. 트리

<details>
<summary>트리와 이진트리, 이진탐색트리에 대해 설명해 주세요</summary>

- 트리는 계층적 구조를 가진 자료구조로, 하나의 루트 노드에서 시작하여 각 노드가 부모-자식 관계로 연결된 형태를 가집니다.
  - 트리는 순환이 존재하지 않으며, 각 노드는 하나의 부모와 0개 이상의 자식을 가질 수 있습니다.
- 이진트리는 트리의 특수한 형태로, 각 노드가 최대 두 개의 자식 노드(왼쪽, 오른쪽)를 가질 수 있는 구조를 의미합니다.
- 이진탐색트리는 이진트리의 일종으로, 각 노드의 값이 특정 정렬 규칙을 따릅니다.
  - 왼쪽 자식 노드의 값은 부모 노드보다 작고,
  - 오른쪽 자식 노드의 값은 부모 노드보다 큽니다.
  - 이러한 규칙 덕분에 이진탐색트리는 탐색, 삽입, 삭제 연산에서 평균적으로 O(log n)의 시간 복잡도를 가집니다.

</details>

<details>
<summary>그래프와 트리의 차이가 무엇인가요?</summary>

- 그래프와 트리의 차이는 연결 방식과 순환 여부에 있습니다.
- 트리는 방향성이 있는 비순환 그래프(DAG; Directed Acyclic Graph)로, 계층적 구조를 가지며 각 노드가 하나의 부모를 가집니다.
- 반면 그래프는 방향성 유무에 관계없이 모든 정점이 서로 자유롭게 연결될 수 있으며, 순환이 존재할 수 있습니다.

</details>

<details>
<summary>이진탐색트리에서 중위 탐색을 하게 되면, 그 결과는 어떤 의미를 가지나요?</summary>

- 이진탐색트리에서 중위 탐색을 수행하면, 트리의 노드를 오름차순으로 정렬된 순서로 방문하게 됩니다.
- 이는 중위 탐색이 왼쪽 자식 → 부모 → 오른쪽 자식 순으로 노드를 방문하기 때문입니다.

</details>

<details>
<summary>이진탐색트리의 값 삽입, 삭제 방법에 대해 설명해주세요</summary>

- 값을 삽입할 때, 새로운 값은 루트에서 시작하여 조건에 맞게 왼쪽 또는 오른쪽 자식으로 이동하며 빈 자리에 삽입됩니다.
- 삭제할 때는 세 가지 상황으로 나뉩니다:
  - 자식이 없는 리프 노드의 경우는 단순히 제거합니다.
  - 자식이 하나인 노드는 자식 노드로 대체합니다.
  - 자식이 두 개인 노드는 오른쪽 서브트리에서 가장 작은 값을 찾아 대체합니다.

</details>

<details>
<summary>이진탐색트리의 주요 연산에 대한 시간복잡도를 설명하고, 왜 그런 시간복잡도가 도출되는지 설명해 주세요</summary>

- 트리의 높이가 log n 이므로, 평균적으로 O(log n)의 시간복잡도를 가집니다.
- 하지만 트리가 불균형 상태가 되면, 최악의 경우 O(n)까지 성능이 저하될 수 있습니다.

</details>

<details>
<summary>이진탐색트리의 한계점에 대해 설명해주세요</summary>

- 이진탐색트리의 한계점은 불균형 상태에서 성능이 크게 저하될 수 있다는 점입니다.
  - 예를 들어, 오름차순/내림차순으로 이미 정렬된 데이터를 순서대로 삽입하면
  - 트리는 편향된 형태가 되어 연결 리스트와 유사한 구조가 되어버리며,
  - 탐색 성능이 O(n)으로 감소합니다.

</details>

<details>
<summary>이진탐색트리와 동일한 로직을 사용하면, 삼진탐색트리도 정의할 수 있을까요? 안 된다면, 그 이유에 대해 설명해 주세요</summary>

- 가능합니다.
- 삼진탐색트리에서는 각 노드가 최대 세 개의 자식을 가질 수 있으며,
  - 왼쪽 자식은 부모보다 작고,
  - 가운데 자식은 부모와 같으며,
  - 오른쪽 자식은 부모보다 큰 값을 가집니다.
- 그렇지만, 최악의 경우 삼진탐색방식은 비교를 더 많이 해야하기에 이진탐색방식이 일반적으로 더 선호됩니다.

</details>

# 6. 힙

<details>
<summary>힙에 대해 설명해주세요</summary>

- 힙은 우선순위가 높은 값이 항상 루트에 위치하는 완전 이진 트리입니다.
- 최대 힙은 큰 값이 루트에, 최소 힙은 작은 값이 루트에 위치합니다.
- 주로 우선순위 큐에서 사용됩니다.

</details>

<details>
<summary>힙을 배열로 구현한다고 가정하면, 어떻게 값을 저장할 수 있을까요?</summary>

- 힙을 배열로 구현할 때, 트리의 계층 구조를 배열 순서로 저장합니다.
- 루트부터 왼쪽 자식, 오른쪽 자식 순으로 채워지며, 완전 이진 트리 형태를 유지합니다.

</details>

<details>
<summary>힙의 삽입, 삭제 방식에 대해 설명하고, 왜 이진탐색트리와 달리 편향이 발생하지 않는지 설명해 주세요</summary>

- 힙에서 삽입은 트리의 가장 끝에 새 값을 추가한 뒤, 부모와 비교하며 적절한 위치로 올라가는 방식으로 처리됩니다. → Heapify Up
- 삭제는 우선순위가 가장 높은 값인 루트를 제거하고, 마지막 값을 루트로 옮긴 뒤 자식과 비교하며 적절한 위치로 내려가는 방식으로 처리됩니다. → Heapify Down
- 힙은 항상 완전 이진 트리를 유지하기 때문에 이진탐색트리처럼 편향 구조가 발생하지 않습니다.

</details>

<details>
<summary>힙 정렬의 시간복잡도는 어떻게 되나요? Stable 한가요?</summary>

- 힙 정렬의 시간복잡도는 O(n log n)입니다.
  - 정렬 + 힙 구성 = 트리 높이 log n × n번 + O(n) (초기 heapify는 무시 가능)
- Stable하지 않습니다.
  - 정렬 과정에서 동일한 값의 상대적 순서가 유지되지 않기 때문입니다.

</details>

# 7. BBST

<details>
<summary>BBST란</summary>

- BBST는 Balanced Binary Search Tree로, 트리의 높이가 항상 O(log n)으로 유지되도록 자동으로 균형을 맞추는 트리 구조입니다.

</details>

<details>
<summary>Red Black Tree는 어떻게 균형을 유지할 수 있을까요?</summary>

![img_jyj.png](img%2Fimg_jyj.png)

- Red-Black Tree는 노드에 Red 또는 Black 색상을 지정하고, 삽입이나 삭제 시 트리의 균형(높이 O(log n))을 유지하기 위해 색상 변경이나 회전 작업을 수행합니다.
  - 회전은 이진탐색트리에서 트리의 특정 노드를 기준으로 부모-자식 관계를 변경하여 균형을 유지하는 작업
- 색상 변경, 좌회전, 우회전, 연속회전의 4가지 방식이 있습니다.

</details>

<details>
<summary>Red Black Tree의 주요 성질 4가지에 대해 설명해 주세요</summary>

- 첫째, 모든 노드는 Red 또는 Black입니다.
- 둘째, 루트 노드는 항상 Black입니다.
- 셋째, Red 노드는 자식이 Red일 수 없습니다.
  - = No Double Red. Red 노드가 연속으로 등장할 수 없습니다.
- 넷째, 모든 리프 노드에서 Black Depth는 같습니다.
  - = 모든 리프 노드에서 루트까지 가는 경로(가지)의 Black 노드 개수는 항상 같습니다.
- 이 네 가지 성질 덕분에 Red-Black Tree는 항상 균형을 유지할 수 있습니다.

</details>

<details>
<summary>2-3-4 Tree, AVL Tree 등의 다른 BBST 가 있음에도, 왜 Red Black Tree가 많이 사용될까요?</summary>

- Red Black Tree가 다른 BBST에 비해 성능이 안정적이고 구현이 간단하기 때문입니다.

  - 삽입과 삭제에서 최대 두 번의 회전으로 균형을 맞출 수 있습니다.
  - 위의 규칙 4: 모든 리프 노드로 가는 경로에서 Black 노드의 개수가 동일하도록 유지하는 규칙 때문에, 트리의 높이 차는 최대 2배를 넘지 않도록 제한됩니다.
    - 루트 기준 bh = 2일 때 최단 경로: Black(루트) - Black - Black(NIL)
    - 최장 경로: Black(루트) → Red → Black → Red → Black(NIL)
  - 색상 변경과 좌우 회전만으로 균형을 유지할 수 있어 코드가 상대적으로 간결합니다.
- 2-3-4 Tree: 각 노드가 최대 4개의 자식과 최대 3개의 값을 가질 수 있는 B-Tree의 일종입니다.

  - 노드의 분할과 병합을 처리하는 로직이 복잡하며, 다중 값과 다중 자식 관리가 필요합니다.
- AVL Tree: 각 노드의 왼쪽, 오른쪽 서브트리 높이 차이가 최대 1로 유지되는 균형 이진 탐색 트리입니다.

  - 노드마다 균형 인수를 유지해야 하며, 삽입/삭제 시 회전 연산이 자주 발생할 수 있습니다.

</details>

# 8. 정렬 알고리즘

<details>
<summary>Quick Sort와 Merge Sort를 비교해 주세요</summary>

- Quick Sort와 Merge Sort는 둘 다 데이터를 나누면서 정렬하는 ‘분할 정복’ 방식의 알고리즘입니다.
- Quick Sort는 기준이 되는 값(pivot)을 중심으로 pivot값보다 작은 값은 왼쪽, 큰 값은 오른쪽으로 데이터를 나누어 정렬하는 알고리즘입니다.
  - 평균적으로 O(n log n)으로 빠르며, 배열 자체에서 정렬이 이루어져서 추가적인 메모리를 거의 사용하지 않는 장점이 있습니다.
  - 다만 최악의 경우에는 시간복잡도가 O(n²)까지 나올 수 있습니다.
- 반면 Merge Sort는 데이터를 반으로 계속 나눠서, 나중에 정렬된 배열끼리 차례로 합쳐가며 정렬합니다.
  - 항상 O(n log n)의 안정적인 성능을 보장하지만, 정렬 시 임시 배열이 필요해서 추가 메모리가 필요합니다.

</details>

<details>
<summary>Quick Sort에서 O(n²)이 걸리는 예시를 들고, 이를 개선할 수 있는 방법에 대해 설명해 주세요</summary>

- Quick Sort는 pivot을 기준으로 데이터를 나누며 정렬하지만, pivot 선택이 좋지 않으면 비효율이 발생할 수 있습니다.
- 예를 들어, 이미 정렬된 배열에서 항상 첫 번째 값을 pivot으로 고르면, 한쪽으로만 계속 나뉘게 되어 분할이 제대로 되지 않습니다. 이 경우 시간복잡도는 최악인 O(n²)이 됩니다.
- 이를 개선하기 위해 앞/중간/끝 중 중간값을 고르는 median-of-three 기법을 사용하면 분할이 더 균형 있게 이루어져 성능 저하를 방지할 수 있습니다.

</details>

<details>
<summary>Stable Sort가 무엇이고, 어떤 정렬 알고리즘이 Stable 한지 설명해 주세요</summary>

- Stable Sort는 값이 같은 요소들이 정렬 후에도 원래의 순서를 유지하는 정렬을 의미합니다.
- Merge Sort는 Stable Sort에 해당하며, Quick Sort는 Stable Sort에 해당하지 않습니다.
- Merge Sort는 병합 과정에서 왼쪽 요소를 먼저 복사하기 때문에 값이 같을 경우에도 입력 순서가 유지되는 반면,
- Quick Sort는 pivot을 기준으로 요소를 분할할 때, 값이 같은 요소들 사이의 상대적인 순서가 바뀔 수 있기 때문입니다.

</details>

<details>
<summary>Merge Sort를 재귀를 사용하지 않고 구현할 수 있을까요?</summary>

- 네, Merge Sort는 재귀 없이도 구현이 가능합니다.
- Bottom-Up 방식이라 부르며, 처음에는 인접한 두 개의 요소부터 병합하고, 이후 점점 더 큰 단위로 병합해 나가는 방식입니다.
- Top-Down 방식은 배열을 반으로 나누는 작업을 재귀적으로 수행합니다.

</details>

<details>
<summary>Radix Sort(기수 정렬)에 대해 설명해 주세요</summary>

- Radix Sort는 자릿수별로 정렬을 반복해 전체 정렬을 완성하는 알고리즘입니다.
- Stable Sort
- 예를 들어 3자리 정수를 정렬할 경우, 1의 자리부터 시작해 10의 자리, 100의 자리 순으로 정렬을 반복합니다.

</details>

<details>
<summary>Bubble, Selection, Insertion Sort의 속도를 비교해 주세요</summary>

- 세 알고리즘 모두 평균 시간복잡도는 O(n²)이나, 실제 수행 속도는 입력 상태에 따라 다르게 나타납니다.
- 일반적인 상황에서는 Insertion Sort가 가장 빠르고, 그 다음이 Selection Sort, 가장 느린 것이 Bubble Sort입니다.
- Bubble Sort는 인접한 값을 반복적으로 교환하며, 전체를 여러 번 훑어야 하기 때문에 가장 느립니다.
- Selection Sort는 가장 작은 값을 선택해서 앞쪽에 배치하는 방식으로, 교환 횟수는 1번이나 비교 횟수가 많아 속도 개선이 어렵습니다.
- Insertion Sort는 정렬된 부분에 값을 삽입하는 방식으로, 데이터가 거의 정렬되어 있을수록 빠르게 동작합니다.

</details>

<details>
<summary>값이 거의 정렬되어 있거나, 아예 정렬되어 있다면, 위 세 알고리즘의 성능 비교 결과는 달라질까요?</summary>

- 넹. Insertion Sort가 가장 좋습니다. → O(n)

</details>

<details>
<summary>본인이 사용하고 있는 언어에선, 어떤 정렬 알고리즘을 사용하여 정렬 함수를 제공하고 있을까요?</summary>

- Java: Arrays.sort(), Collections.sort()

  - 기본형 배열 (int[], double[] 등): Dual-Pivot QuickSort 사용
  - 평균적으로 빠르며, 비교 기반 정렬 중 성능이 우수함
  - 객체 배열 (Integer[], String[] 등): TimSort 사용
    - 객체는 값뿐 아니라 원래 순서가 의미 있는 경우가 많음 → 안정 정렬
    - TimSort는 Merge Sort와 Insertion Sort를 결합한 하이브리드 알고리즘
- Python: sorted(), list.sort()

  - Timsort 사용

</details>

<details>
<summary>정렬해야 하는 데이터는 50G 인데, 메모리가 4G라면, 어떤 방식으로 정렬을 진행할 수 있을까요?</summary>

- 데이터가 메모리보다 훨씬 큰 경우이므로, 데이터를 4GB 단위로 나누어 각각 정렬한 후, 정렬된 블록들을 다시 병합합니다. (External Merge Sort)
- 이 과정에서 디스크 입출력이 병목이 되지 않도록 버퍼를 잘 활용해야 합니다.

</details>

# 9~10. 그래프

<details>
<summary>그래프 자료구조에 대해 설명하고, 이를 구현할 수 있는 두 방법에 대해 설명해 주세요</summary>

- 그래프는 정점(Vertex)과 간선(Edge)으로 구성되는 자료구조입니다.
- 그래프를 구현하는 대표적인 두 가지 방법은 인접 행렬(Adjacency Matrix)과 인접 리스트(Adjacency List)입니다.
  - 인접 행렬은 N×N 크기의 2차원 배열을 사용하여, 두 정점 사이에 간선이 있는지를 0 또는 1로 표시합니다.
  - 인접 리스트는 각 정점마다 연결된 정점들의 리스트를 따로 저장합니다.

</details>

<details>
<summary>각 방법에 대해, "두 정점이 연결되었는지" 확인하는 시간복잡도와 "한 정점에 연결된 모든 정점을 찾는" 시간복잡도, 그리고 공간복잡도를 비교해 주세요</summary>

- 인접 행렬 (Adjacency Matrix)

  - 두 정점이 연결되었는지 확인: O(1)
  - 한 정점에 연결된 모든 정점 찾기: O(N)
  - 공간복잡도: O(N²)
- 인접 리스트 (Adjacency List)

  - 두 정점이 연결되었는지 확인: O(k) (k는 해당 정점의 간선 수)
  - 한 정점에 연결된 모든 정점 찾기: O(k)
  - 공간복잡도: O(N + E) (E는 간선의 수)

</details>

<details>
<summary>정점의 개수가 N개, 간선의 개수가 N³ 개라면, 어떤 방식으로 구현하는 것이 효율적일까요?</summary>

- 정점의 개수가 N개이고 간선이 N³개인 경우, 그래프가 매우 밀집(dense) 되어 있기 때문에, 인접 행렬(Adjacency Matrix) 방식으로 구현하는 것이 더 효율적입니다.
- 인접 리스트는 간선이 너무 많아 각 정점의 리스트가 지나치게 길어지고, 탐색 시 시간과 공간 낭비가 커질 수 있습니다.
- 반면 인접 행렬은 연결 여부를 O(1) 시간에 확인할 수 있습니다.

</details>

<details>
<summary>사이클이 없는 그래프는 모두 트리인가요? 그렇지 않다면, 예시를 들어주세요</summary>

- 사이클이 없다고 해서 모두 트리는 아닙니다. (연결되지 않는 정점이 있는 경우)
- 예시:
  - 정점이 4개이고 간선이 2개인 그래프 (1-2, 3-4)는
  - 사이클은 없지만 연결되어 있지 않기 때문에 트리가 아닙니다.

</details>

# 11. 재귀함수

<details>
<summary>재귀함수에 대해 설명해 주세요</summary>

- 재귀 함수는 함수 내부에서 **자기 자신을 호출**하여 반복 작업을 처리하는 방식입니다.
- 백트래킹, DFS, N-Queen 문제
  > N-Queen 문제: N×N 체스판에 퀸 N개를 서로 공격하지 않도록 놓는 경우의 수를 구하는 문제입니다. 퀸은 가로, 세로, 대각선 방향으로 공격하므로,**같은 행, 같은 열, 같은 대각선에 퀸이 겹치지 않도록 배치해야 합니다.**
  > - 이 문제는 백트래킹 기법을 사용하는 재귀 알고리즘으로 풀이합니다.
  > - 각 행에 퀸을 하나씩 놓으면서, **이전에 놓인 퀸들과 충돌하지 않는 위치만 탐색**하고,
  > - 만약 더 이상 유효한 위치가 없으면 재귀 호출을 빠져나와 이전 상태로 되돌아가 다른 선택지를 시도합니다.

</details>

<details>
<summary>재귀 함수의 동작 과정을 Call Stack을 활용해서 설명해 주세요</summary>

- 재귀 함수는 호출될 때마다 Call Stack에 쌓이며,
- 가장 깊은 호출부터 차례로 결과를 반환하며 Stack이 거꾸로 정리되는 구조로 동작합니다.
> 함수 안에서 다른 함수가 호출되었을 때 레지스터의 값을 caller와 callee중 누가 저장해야 하는 책임이 있는지
> - **Caller-saved register** (비보존 레지스터):
> - → 함수 호출 전, **caller가 저장**해야 함
> - **Callee-saved register** (보존 레지스터):
> - → 함수 호출 중에 사용 시, **callee가 저장하고 복구**해야 함

</details>

<details>
<summary>언어의 스펙에 따라, 재귀함수의 최적화를 진행해주는 경우가 있습니다. 어떤 경우에 재귀함수의 최적화가 가능하며, 이를 어떻게 최적화 할 수 있을지 설명해 주세요</summary>

- 마지막 연산이 재귀 호출인 경우(꼬리 재귀)에는 이전 상태를 보관할 필요가 없어 호출 스택을 쌓지 않고 반복문처럼 처리하는 최적화 방식(TCO)이 가능
- 일부 함수형 언어(Scheme, Haskell, Scala 등)에서는 이를 자동으로 적용
- C/C++이나 Kotlin에서는 컴파일러나 키워드를 통해 제한적으로 지원
- Java나 Python은 기본적으로 TCO를 지원하지 X

</details>

# 12. MST

<details>
<summary>MST가 무엇이고, 어떻게 구할 수 있을지 설명해 주세요</summary>

- 최소신장트리는 모든 정점을 연결하면서 간선의 가중치 합이 최소인 트리를 의미합니다.
- 사이클 없이 모든 정점을 잇는 구조이며, 대표적인 알고리즘으로는 크루스칼(Kruskal) 과 프림(Prim) 알고리즘이 있습니다.

</details>

<details>
<summary>Kruskal 알고리즘에서 사용하는 Union-Find 자료구조에 대해 설명해 주세요</summary>

- Union-Find는 서로소 집합(Disjoint Set)을 표현하는 자료구조입니다.
    - Find: 어떤 노드가 속한 집합의 루트 노드를 찾음
    - Union: 두 집합을 하나로 합침
- Kruskal 알고리즘에서는 사이클 생성을 방지하기 위해, 두 정점이 같은 집합에 속해 있는지를 확인하고 서로 다른 집합이면 연결(Union), 같은 집합이면 무시합니다.

- 최적화 기법
    - 경로 압축 (Path Compression): Find 시 트리 깊이를 줄이기 위해, 방문한 노드를 루트에 직접 연결
    - 랭크 기준 합치기 (Union by Rank): 트리의 높이가 더 낮은 쪽을 높은 쪽에 붙임

</details>

<details>
<summary>Kruskal 과 Prim 알고리즘을 통해 얻어진 결과물은 무조건 트리인가요? 만약 그렇다면 증명해 주세요. 그렇지 않다면, 반례를 설명해 주세요</summary>

- 네, 무조건 트리입니다.
- 이유는 다음과 같습니다:
    - 모든 정점을 연결해야 하므로 연결 그래프
    - 사이클이 없어야 하므로 비순환
    - 따라서, **사이클 없는 연결 그래프 = 트리**

</details>

# 13. Thread Safe

<details>
<summary>Thread Safe 한 자료구조가 있을까요? 없다면, 어떻게 Thread Safe 하게 구성할 수 있을까요?</summary>

- Thread Safe하다는 건, 여러 쓰레드가 같은 변수나 자료구조에 동시에 접근해도 데이터가 꼬이지 않고 안전하게 작동하는 걸 말합니다.
- 언어에 따라 Thread Safe한 자료구조가 기본적으로 제공되기도 하며,
- 제공되지 않는 경우에는 동기화(synchronization) 또는 락(lock) 을 사용하여 직접 구성할 수 있습니다.

</details>

<details>
<summary>배열의 길이를 알고 있다면, 조금 더 빠른 Thread Safe 한 연산을 만들 순 없을까요?</summary>

- 네, 배열의 길이가 고정되어 있다면 각 쓰레드가 자기 전용 인덱스에게만 접근하도록 하여 락 없이도 Thread Safe한 연산이 가능합니다.
- 또한 락을 전체 배열에 걸지 않고도 부분 인덱스 단위로 쪼개는 **lock striping 방식**을 활용하면 성능을 향상시킬 수 있습니다.

</details>

<details>
<summary>사용하고 있는 언어의 자료구조는 Thread Safe 한가요? 그렇지 않다면, Thread Safe 한 Wrapped Data Structure 를 제공하고 있나요?</summary>

- Java에서는 ArrayList, HashMap 등 기본 컬렉션은 Thread Safe 하지 않지만,
    - `Collections.synchronizedList()`나
    - `ConcurrentHashMap`과 같이 Thread Safe 한 래퍼 또는 대안 클래스가 별도로 제공됩니다.

- Python에서는 기본 리스트나 딕셔너리는 Thread Safe 하지 않지만,
    - `queue.Queue`
    - `multiprocessing.Manager().list()` 등의 구조를 통해 안전하게 병렬 접근이 가능합니다.

</details>

---
# ToDo..
# 14. 문자열 처리 자료구조

<details>
<summary> 문자열을 저장하고, 처리하는 주요 자료구조 및 알고리즘 (Trie, KMP, Rabin Karp 등) 에 대해 설명해 주세요</summary>
</details>

# 15. 이진탐색

<details>
<summary>이진탐색이 무엇인지 설명하고, 시간복잡도를 증명해 보세요</summary>
</details>

<details>
<summary>Lower Bound, Upper Bound 는 무엇이고, 이를 어떻게 구현할 수 있을까요?</summary>
</details>

<details>
<summary>이진탐색의 논리를 적용하여 삼진탐색을 작성한다고 가정한다면, 시간복잡도는 어떻게 변화할까요? (실제 존재하는 삼진탐색 알고리즘은 무시하세요!)</summary>
</details>

<details>
<summary>기존 이진탐색 로직에서 부등호의 범위가 바뀐다면, (ex. <= 라면 <로, <이라면 <= 로) 결과가 달라질까요?</summary>
</details>

# 16. 그리디, DP

<details>
<summary>그리디 알고리즘과 동적 계획법을 비교해 주세요</summary>
</details>

<details>
<summary>그렇다면, 어떤 경우에 각각의 기법을 사용할 수 있을까요?</summary>
</details>

<details>
<summary>그렇다면, 동적 계획법으로 풀 수 있는 모든 문제는 재귀로 변환하여 풀 수 있나요?</summary>
</details>